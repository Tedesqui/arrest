<!DOCTYPE html>
<html lang="pt-BR">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Reconhecimento Facial com Zoom</title>

    <style>
        body, html {
            margin: 0;
            overflow: hidden; /* Evita barras de rolagem */
            font-family: Arial, sans-serif;
            background: black;
            color: white;
            display: flex;
            flex-direction: column; /* Para posicionar os controles */
            align-items: center;
            justify-content: center;
            min-height: 100vh;
        }

        /* Estilo para o elemento de vídeo (feed da câmera) */
        video {
            position: fixed;
            top: 0;
            left: 0;
            width: 100vw; /* Ocupa 100% da largura da viewport */
            height: 100vh; /* Ocupa 100% da altura da viewport */
            object-fit: cover; /* Cobre toda a área sem distorcer, cortando se necessário */
            z-index: 0; /* Fica no fundo */
        }

        /* Estilo para o canvas de detecção (gerado pela face-api.js) */
        canvas {
            position: fixed;
            top: 0;
            left: 0;
            z-index: 1; /* Fica acima do vídeo */
            pointer-events: none; /* Permite cliques "atravessarem" o canvas */
        }

        /* Estilo para a caixa de informações/status */
        #info {
            position: fixed;
            bottom: 20px;
            left: 50%;
            transform: translateX(-50%); /* Centraliza horizontalmente */
            background: rgba(0, 0, 0, 0.7); /* Fundo semi-transparente */
            color: white;
            padding: 15px;
            border-radius: 10px;
            font-size: 1.1rem; /* Um pouco maior para melhor leitura */
            text-align: center;
            z-index: 2; /* Fica acima do canvas */
            max-width: 90%; /* Limita a largura para melhor leitura em telas grandes */
            white-space: pre-line; /* Preserva quebras de linha no texto */
            box-shadow: 0 4px 10px rgba(0, 0, 0, 0.3); /* Sombra para destaque */
        }

        /* Estilo para o contêiner de controles (botões) */
        #controls {
            position: fixed;
            top: 10px;
            right: 10px;
            z-index: 3; /* Fica acima de todos os outros elementos */
        }

        /* Estilo para os botões */
        button {
            font-size: 18px;
            padding: 10px 18px;
            background: #007bff; /* Cor azul padrão */
            color: white;
            border: none;
            border-radius: 30px; /* Botão mais arredondado */
            cursor: pointer;
            box-shadow: 0 4px 8px rgba(0, 0, 0, 0.2); /* Sombra para o botão */
            transition: background-color 0.2s ease, transform 0.1s ease;
        }

        button:hover {
            background-color: #0056b3; /* Azul mais escuro ao passar o mouse */
            transform: translateY(-2px); /* Efeito de "levantar" */
        }

        button:active {
            transform: translateY(0); /* Retorna à posição normal ao clicar */
        }

        button:disabled {
            background-color: #6c757d; /* Cinza quando desabilitado */
            cursor: not-allowed;
            opacity: 0.7;
            box-shadow: none;
        }
    </style>
</head>
<body>

    <video id="video" autoplay muted playsinline></video>

    <canvas id="drawingCanvas"></canvas>

    <div id="info">Carregando IA e modelos...</div>

    <div id="controls">
        <button id="zoomToggleBtn" disabled>Zoom</button>
    </div>

    <script src="https://cdn.jsdelivr.net/npm/face-api.js"></script>
    <script>
        // --- 1. Seletores de Elementos HTML ---
        const video = document.getElementById("video");
        const drawingCanvas = document.getElementById("drawingCanvas");
        const info = document.getElementById("info");
        const zoomToggleBtn = document.getElementById('zoomToggleBtn');

        // --- 2. Dados de Pessoas para Reconhecimento ---
        const people = [
            { name: "Joao", info: "Professor de Matemática, 35 anos", images: 7 },
            { name: "Maria", info: "Arquiteta, 29 anos", images: 3 },
            { name: "Carlos", info: "Engenheiro, 41 anos", images: 3 }
        ];

        // --- 3. Variáveis de Controle da Câmera e Zoom ---
        let mediaTrack;
        let zoomCapabilities = {};
        let currentZoom = 1.0;
        let zoomDirection = 1;
        const ZOOM_INCREMENT_FACTOR = 0.5;

        // --- 4. Funções Assíncronas ---

        async function loadLabeledImages() {
            updateInfoStatus("Carregando imagens de treinamento...");
            const labeledDescriptors = await Promise.all(
                people.map(async person => {
                    const descriptors = [];
                    for (let i = 1; i <= person.images; i++) {
                        const imgPath = `labeled/${person.name}/${i}.jpg`;
                        try {
                            const img = await faceapi.fetchImage(imgPath);
                            const detection = await faceapi.detectSingleFace(img)
                                .withFaceLandmarks()
                                .withFaceDescriptor();
                            if (detection) {
                                descriptors.push(detection.descriptor);
                            }
                        } catch (err) {
                            console.warn(`Erro ao carregar ou processar imagem ${imgPath} para ${person.name}:`, err);
                        }
                    }
                    if (descriptors.length === 0) {
                        console.warn(`Nenhum descritor encontrado para ${person.name}. Verifique se as imagens estão corretas em 'labeled/${person.name}/'.`);
                    }
                    return new faceapi.LabeledFaceDescriptors(person.name, descriptors);
                })
            );
            // Verifica se há pelo menos um descritor válido para alguma pessoa
            if (labeledDescriptors.every(ld => ld.descriptors.length === 0)) {
                throw new Error("Nenhuma pessoa reconhecível configurada. Verifique as imagens em 'labeled/'.");
            }
            return labeledDescriptors;
        }

        async function startCamera() {
            try {
                const stream = await navigator.mediaDevices.getUserMedia({
                    video: true // Não especifica facingMode; o navegador escolherá a câmera.
                });
                video.srcObject = stream;

                await new Promise(resolve => video.onloadedmetadata = resolve);

                mediaTrack = stream.getVideoTracks()[0];

                if (mediaTrack && typeof mediaTrack.getCapabilities === 'function') {
                    zoomCapabilities = mediaTrack.getCapabilities();
                    if (zoomCapabilities.zoom) {
                        const { min, current } = zoomCapabilities.zoom;
                        currentZoom = current || min;
                        zoomToggleBtn.disabled = false;
                        console.log('Capacidades de Zoom:', zoomCapabilities.zoom);
                        updateInfoStatus(`Câmera iniciada. Zoom: ${currentZoom.toFixed(2)}x`);
                    } else {
                        updateInfoStatus('Câmera iniciada. Zoom não suportado neste dispositivo.');
                        zoomToggleBtn.disabled = true;
                    }
                } else {
                    updateInfoStatus('Câmera iniciada. Navegador não suporta controle de zoom.');
                    zoomToggleBtn.disabled = true;
                }

            } catch (err) {
                console.error("Erro ao acessar a câmera:", err);
                updateInfoStatus(`Erro: Câmera não acessível. ${err.message}. Verifique as permissões.`);
                zoomToggleBtn.disabled = true;
                // Não há botão "Corrigir", então não precisa desabilitar nada mais aqui.
            }
        }

        async function applyZoom(targetZoom) {
            if (!mediaTrack || !zoomCapabilities.zoom) {
                updateInfoStatus("Zoom não suportado ou câmera não iniciada.");
                return;
            }

            const { min, max, step } = zoomCapabilities.zoom;
            let newZoom = Math.max(min, Math.min(max, targetZoom));

            if (step && step > 0) {
                newZoom = Math.round(newZoom / step) * step;
            }

            try {
                await mediaTrack.applyConstraints({
                    advanced: [{ zoom: newZoom }]
                });
                currentZoom = newZoom;
                updateInfoStatus(`Zoom: ${currentZoom.toFixed(2)}x`);

                if (currentZoom >= max) {
                    zoomToggleBtn.textContent = "Redefinir Zoom";
                } else if (currentZoom <= min) {
                    zoomToggleBtn.textContent = "Zoom +";
                } else {
                    zoomToggleBtn.textContent = "Zoom +/-";
                }

            } catch (err) {
                console.error('Erro ao aplicar zoom:', err);
                updateInfoStatus(`Erro ao aplicar zoom: ${err.message}`);
            }
        }

        async function toggleZoom() {
            if (!mediaTrack || !zoomCapabilities.zoom) {
                updateInfoStatus("Zoom não suportado pela câmera ou navegador.");
                return;
            }

            const { min, max, step } = zoomCapabilities.zoom;
            let nextZoom;
            const increment = step || (max - min) * ZOOM_INCREMENT_FACTOR;

            if (zoomDirection === 1) {
                nextZoom = currentZoom + increment;
                if (nextZoom >= max) {
                    nextZoom = max;
                    zoomDirection = -1;
                }
            } else {
                nextZoom = min;
                zoomDirection = 1;
            }

            await applyZoom(nextZoom);
        }

        function updateInfoStatus(message) {
            info.innerText = message;
        }

        /**
         * Inicializa a aplicação:
         * 1. Carrega os modelos de IA da Face-API.js.
         * 2. Inicia o feed da câmera e configura o zoom.
         * 3. Carrega e processa as imagens de treinamento para reconhecimento.
         * 4. Configura o loop principal de detecção e reconhecimento facial.
         */
        async function initApp() {
            updateInfoStatus("Carregando modelos de IA...");
            try {
                // Certifica-se que a biblioteca faceapi está carregada.
                // O check 'typeof faceapi === "undefined"' pode ser útil em cenários complexos,
                // mas mover a tag script da face-api.js para antes do seu script principal já ajuda muito.
                if (typeof faceapi === "undefined") {
                    throw new Error("A biblioteca face-api.js não foi carregada. Verifique o CDN.");
                }

                await Promise.all([
                    faceapi.nets.tinyFaceDetector.loadFromUri("https://cdn.jsdelivr.net/npm/face-api.js/weights"),
                    faceapi.nets.faceLandmark68Net.loadFromUri("https://cdn.jsdelivr.net/npm/face-api.js/weights"),
                    faceapi.nets.faceRecognitionNet.loadFromUri("https://cdn.jsdelivr.net/npm/face-api.js/weights")
                ]);
            } catch (err) {
                console.error("Erro ao carregar modelos da face-api.js:", err);
                updateInfoStatus(`Erro: Falha ao carregar modelos de IA. ${err.message}.`);
                return;
            }

            await startCamera();

            let labeledDescriptors;
            try {
                labeledDescriptors = await loadLabeledImages();
            } catch (err) {
                console.error("Erro ao carregar imagens rotuladas:", err);
                updateInfoStatus(`Erro: ${err.message}`);
                return;
            }

            const matcher = new faceapi.FaceMatcher(labeledDescriptors, 0.6);

            updateInfoStatus(`Pronto! Aproxime um rosto da câmera. Zoom: ${currentZoom.toFixed(2)}x`);

            video.addEventListener("play", () => {
                drawingCanvas.width = video.videoWidth;
                drawingCanvas.height = video.videoHeight;
                const ctx = drawingCanvas.getContext("2d");

                setInterval(async () => {
                    const detections = await faceapi.detectAllFaces(video, new faceapi.TinyFaceDetectorOptions())
                        .withFaceLandmarks()
                        .withFaceDescriptors();

                    const resizedDetections = faceapi.resizeResults(detections, { width: drawingCanvas.width, height: drawingCanvas.height });

                    ctx.clearRect(0, 0, drawingCanvas.width, drawingCanvas.height);
                    faceapi.draw.drawDetections(drawingCanvas, resizedDetections);

                    if (detections.length > 0) {
                        let foundPeopleInfo = [];
                        resizedDetections.forEach(det => {
                            const bestMatch = matcher.findBestMatch(det.descriptor);
                            const person = people.find(p => p.name === bestMatch.label);

                            if (person) {
                                foundPeopleInfo.push(`${person.name} - ${person.info}`);
                            } else {
                                foundPeopleInfo.push("Pessoa não reconhecida");
                            }
                        });
                        updateInfoStatus(foundPeopleInfo.join('\n\n'));
                    } else {
                        updateInfoStatus("Nenhum rosto detectado.");
                    }
                }, 1000); // Intervalo de 1 segundo para detecção.
            });
        }

        // --- 5. Event Listeners ---
        zoomToggleBtn.addEventListener('click', toggleZoom);

        // --- 6. Inicialização da Aplicação ---
        // Garante que o DOM esteja completamente carregado antes de iniciar a aplicação.
        document.addEventListener('DOMContentLoaded', initApp);
    </script>
</body>
</html>
