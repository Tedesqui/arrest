<!DOCTYPE html>
<html lang="pt-BR">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Reconhecimento Facial AR</title>
  <script defer src="https://cdn.jsdelivr.net/npm/face-api.js"></script>
  <style>
    body, html { margin: 0; padding: 0; height: 100%; background: #000; font-family: Arial, sans-serif; }
    video, canvas { position: fixed; top: 0; left: 0; width: 100%; height: 100%; object-fit: cover; }
    #info {
      position: fixed; bottom: 20px; left: 50%; transform: translateX(-50%);
      background: rgba(0,0,0,0.6); color: white; padding: 10px 15px;
      border-radius: 8px; font-size: 16px; z-index: 3;
    }
    #controls {
      position: fixed; top: 10px; right: 10px; z-index: 4;
    }
    button {
      background: #007bff; color: white; border: none;
      padding: 10px 15px; border-radius: 8px; cursor: pointer;
    }
  </style>
</head>
<body>

  <video id="video" autoplay muted playsinline></video>
  <canvas id="overlay"></canvas>
  <div id="info">Carregando modelos...</div>
  <div id="controls">
    <button id="zoomBtn">Zoom</button>
  </div>

  <script>
    const video = document.getElementById('video');
    const canvas = document.getElementById('overlay');
    const info = document.getElementById('info');
    const zoomBtn = document.getElementById('zoomBtn');

    const people = [
      { name: "Joao", info: "Professor, 35 anos", images: 3 },
      { name: "Maria", info: "Arquiteta, 29 anos", images: 3 },
      { name: "Carlos", info: "Engenheiro, 40 anos", images: 3 }
    ];

    let zoomLevel = 1;
    let mediaTrack;

    async function startCamera() {
      try {
        const stream = await navigator.mediaDevices.getUserMedia({ video: { facingMode: 'environment' } });
        video.srcObject = stream;
        mediaTrack = stream.getVideoTracks()[0];
      } catch (err) {
        info.innerText = 'Erro: ' + err.message;
      }
    }

    async function loadImages() {
      return Promise.all(
        people.map(async p => {
          const descriptors = [];
          for (let i = 1; i <= p.images; i++) {
            const img = await faceapi.fetchImage(`labeled/${p.name}/${i}.jpg`);
            const detection = await faceapi.detectSingleFace(img).withFaceLandmarks().withFaceDescriptor();
            if (detection) descriptors.push(detection.descriptor);
          }
          return new faceapi.LabeledFaceDescriptors(p.name, descriptors);
        })
      );
    }

    async function init() {
      await faceapi.nets.tinyFaceDetector.loadFromUri('https://cdn.jsdelivr.net/npm/face-api.js/weights');
      await faceapi.nets.faceLandmark68Net.loadFromUri('https://cdn.jsdelivr.net/npm/face-api.js/weights');
      await faceapi.nets.faceRecognitionNet.loadFromUri('https://cdn.jsdelivr.net/npm/face-api.js/weights');

      await startCamera();
      info.innerText = 'Carregando imagens...';

      const labeledDescriptors = await loadImages();
      const matcher = new faceapi.FaceMatcher(labeledDescriptors, 0.6);

      video.addEventListener('play', () => {
        canvas.width = video.videoWidth;
        canvas.height = video.videoHeight;
        const ctx = canvas.getContext('2d');

        setInterval(async () => {
          const detections = await faceapi.detectAllFaces(video, new faceapi.TinyFaceDetectorOptions())
            .withFaceLandmarks()
            .withFaceDescriptors();

          const resized = faceapi.resizeResults(detections, { width: canvas.width, height: canvas.height });
          ctx.clearRect(0, 0, canvas.width, canvas.height);
          faceapi.draw.drawDetections(canvas, resized);

          const results = resized.map(d => {
            const best = matcher.findBestMatch(d.descriptor);
            const person = people.find(p => p.name === best.label);
            return person ? `${person.name} - ${person.info}` : 'Pessoa nÃ£o reconhecida';
          });

          info.innerText = results.length ? results.join('\n\n') : 'Nenhum rosto detectado';

        }, 1500);
      });
    }

    function toggleZoom() {
      if (!mediaTrack) return;
      const capabilities = mediaTrack.getCapabilities();
      if (capabilities.zoom) {
        zoomLevel = zoomLevel >= 3 ? 1 : zoomLevel + 1;
        mediaTrack.applyConstraints({ advanced: [{ zoom: zoomLevel }] });
      }
    }

    zoomBtn.addEventListener('click', toggleZoom);

    window.addEventListener('load', init);
  </script>
</body>
</html>
