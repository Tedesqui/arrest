<!DOCTYPE html>
<html lang="pt-br">
<head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Detecção de Partes Danificadas (TensorFlow.js) com Zoom Único</title>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@4.2.0"></script>

    <style>
        body {
            margin: 0;
            overflow: hidden;
            font-family: Arial, sans-serif;
            display: flex;
            flex-direction: column;
            justify-content: center;
            align-items: center;
            min-height: 100vh;
            background-color: #f0f0f0;
        }
        video, canvas {
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            object-fit: cover;
        }
        #status {
            position: absolute;
            top: 10px;
            left: 10px;
            color: white;
            background: rgba(0, 0, 0, 0.7);
            padding: 8px 12px;
            border-radius: 5px;
            font-size: 16px;
            z-index: 10;
        }
        #controls {
            position: absolute;
            bottom: 20px;
            left: 50%;
            transform: translateX(-50%);
            display: flex;
            gap: 15px;
            z-index: 10;
        }
        button {
            padding: 12px 25px;
            font-size: 16px;
            cursor: pointer;
            border: none;
            border-radius: 30px;
            background-color: #007bff;
            color: white;
            box-shadow: 0 4px 8px rgba(0, 0, 0, 0.2);
            transition: background-color 0.3s ease, transform 0.2s ease;
            outline: none;
        }
        button:hover {
            background-color: #0056b3;
            transform: translateY(-2px);
        }
        button:active {
            transform: translateY(1px);
        }
        button:disabled {
            background-color: #cccccc;
            cursor: not-allowed;
            box-shadow: none;
        }
    </style>
</head>
<body>
    <div id="status">Carregando modelo...</div>

    <video id="video" width="640" height="480" autoplay muted playsinline></video>

    <canvas id="canvas" width="640" height="480"></canvas>

    <div id="controls">
        <button id="zoomToggleBtn">Zoom</button>
    </div>

    <script>
        // --- 1. Seletores de Elementos HTML ---
        const video = document.getElementById('video');
        const canvas = document.getElementById('canvas');
        const ctx = canvas.getContext('2d');
        const statusEl = document.getElementById('status');
        const zoomToggleBtn = document.getElementById('zoomToggleBtn');

        let model; // Variável para armazenar o modelo de IA carregado
        let videoTrack; // Para armazenar a trilha de vídeo da câmera para controle de zoom
        let zoomCapabilities = {}; // Armazena as capacidades de zoom da câmera
        let currentZoom = 1.0; // Zoom inicial (normalmente o mínimo)
        let zoomDirection = 1; // 1 para aumentar, -1 para diminuir ou redefinir

        // !!! Importante: Mapeamento de IDs de classe para nomes legíveis
        // Este array deve corresponder aos nomes das suas classes no Roboflow na ordem correta dos IDs.
        const classNames = [
            'fundo', // ID 0 (geralmente background ou uma classe não relevante)
            'retrovisor_danificado', // ID 1
            'porta_danificada', // ID 2
            // Adicione mais classes conforme seu modelo
        ];

        // --- 2. Funções Assíncronas ---

        /**
         * Inicia o stream de vídeo da câmera do usuário e configura o zoom.
         */
        async function startCamera() {
            try {
                // Solicita acesso à câmera (pode ser configurado para facingMode: 'environment' para câmera traseira)
                const stream = await navigator.mediaDevices.getUserMedia({ video: true });
                video.srcObject = stream;

                // Garante que o vídeo esteja carregado antes de tentar desenhar
                await new Promise(resolve => video.onloadedmetadata = resolve);

                // Ajusta o tamanho do canvas para corresponder ao vídeo
                canvas.width = video.videoWidth;
                canvas.height = video.videoHeight;
                ctx.clearRect(0, 0, canvas.width, canvas.height); // Limpa o canvas

                // Obtém a trilha de vídeo para controlar o zoom
                videoTrack = stream.getVideoTracks()[0];

                // Verifica as capacidades de zoom
                if (videoTrack && typeof videoTrack.getCapabilities === 'function') {
                    zoomCapabilities = videoTrack.getCapabilities();
                    if (zoomCapabilities.zoom) {
                        const { min, current } = zoomCapabilities.zoom;
                        currentZoom = current || min; // Inicia com o zoom atual ou mínimo
                        console.log('Capacidades de Zoom:', zoomCapabilities.zoom);
                        zoomToggleBtn.disabled = false; // Habilita o botão de zoom
                        statusEl.textContent = `Zoom: ${currentZoom.toFixed(2)}x`;
                    } else {
                        statusEl.textContent = 'A câmera não suporta controle de zoom programático.';
                        zoomToggleBtn.disabled = true;
                    }
                } else {
                    statusEl.textContent = 'O navegador não suporta controle de zoom programático.';
                    zoomToggleBtn.disabled = true;
                }

            } catch (err) {
                console.error('Erro ao acessar a câmera:', err);
                statusEl.textContent = `Erro: Câmera não acessível. ${err.message}`;
                zoomToggleBtn.disabled = true;
            }
        }

        /**
         * Carrega o modelo de detecção de objetos customizado.
         */
        async function loadModel() {
            statusEl.textContent = "Carregando modelo de IA...";
            try {
                // Carrega o modelo exportado (assumindo que 'model.json' está na mesma pasta)
                model = await tf.loadGraphModel('./model.json');
                statusEl.textContent = "Modelo carregado! Iniciando detecção...";
                detectFrame(); // Inicia o loop de detecção assim que o modelo é carregado
            } catch (err) {
                console.error('Erro ao carregar o modelo de IA:', err);
                statusEl.textContent = `Erro: Falha ao carregar o modelo. ${err.message}`;
            }
        }

        /**
         * Loop principal de detecção de objetos em cada frame do vídeo.
         */
        async function detectFrame() {
            tf.engine().startScope(); // Inicia um escopo para gerenciar a memória do TensorFlow.js

            ctx.drawImage(video, 0, 0, canvas.width, canvas.height); // Desenha o frame do vídeo no canvas

            // Converte o frame do canvas para um tensor de imagem
            const imgTensor = tf.browser.fromPixels(canvas).expandDims(0).toFloat().div(255);

            // Realiza a inferência (detecção) usando o modelo
            const result = await model.executeAsync(imgTensor);

            // Extrai os dados dos resultados (caixas, pontuações, classes, número de detecções)
            const [boxes, scores, classes, numDetections] = result.map(t => t.dataSync());

            // Limiar de confiança para exibir detecções
            const detectionThreshold = 0.6;

            // Limpa o canvas e redesenha o vídeo para evitar artefatos de "limpeza"
            ctx.clearRect(0, 0, canvas.width, canvas.height);
            ctx.drawImage(video, 0, 0, canvas.width, canvas.height);

            // Itera sobre as detecções para desenhar caixas e exibir informações
            for (let i = 0; i < numDetections[0]; i++) {
                const score = scores[i];
                if (score > detectionThreshold) {
                    // Coordenadas da caixa delimitadora (y1, x1, y2, x2)
                    const [y1, x1, y2, x2] = boxes.slice(i * 4, (i + 1) * 4);
                    const labelId = Math.round(classes[i]); // A classe detectada (arredonda se for float)

                    // Mapeia o ID da classe para o nome legível
                    const label = classNames[labelId] || `Classe Desconhecida (${labelId})`;

                    // Ajusta as coordenadas para o tamanho do canvas
                    const x = x1 * canvas.width;
                    const y = y1 * canvas.height;
                    const width = (x2 - x1) * canvas.width;
                    const height = (y2 - y1) * canvas.height;

                    // Desenha a caixa delimitadora
                    ctx.strokeStyle = "red";
                    ctx.lineWidth = 2;
                    ctx.strokeRect(x, y, width, height);

                    // Desenha o texto da detecção
                    ctx.fillStyle = "red";
                    ctx.font = "14px Arial";
                    ctx.fillText(`${label}: ${(score * 100).toFixed(1)}%`, x, y > 10 ? y - 5 : y + 15);

                    if (label === "retrovisor_danificado") {
                        window.location.href = "https://www.seusite.com/retrovisor";
                    } else if (label === "porta_danificada") {
                        window.location.href = "https://www.seusite.com/porta";
                    }
                    */
                }
            }

            tf.engine().endScope(); // Limpa a memória usada pelo TensorFlow.js neste escopo
            requestAnimationFrame(detect); // Chama a próxima iteração do loop
        }

        /**
         * Alterna o nível de zoom da câmera (aumenta ou redefine).
         */
        async function toggleZoom() {
            if (!videoTrack || !zoomCapabilities.zoom) {
                statusEl.textContent = "Zoom não suportado pela câmera ou navegador.";
                return;
            }

            const { min, max, step } = zoomCapabilities.zoom;
            let targetZoom;
            const zoomIncrement = step || 0.1; // Define um incremento padrão se 'step' não estiver disponível

            if (zoomDirection === 1) { // Aumentar o zoom
                targetZoom = currentZoom + zoomIncrement;
                if (targetZoom >= max) {
                    targetZoom = max;
                    zoomDirection = -1; // Inverte a direção para diminuir no próximo clique
                }
            } else { // Diminuir ou redefinir o zoom
                targetZoom = min; // Volta para o zoom mínimo
                zoomDirection = 1; // Inverte a direção para aumentar no próximo clique
            }

            // Garante que o zoom esteja dentro dos limites e ajusta ao passo mais próximo
            targetZoom = Math.max(min, Math.min(max, targetZoom));
            if (step && step > 0) {
                 targetZoom = Math.round(targetZoom / step) * step;
            }

            console.log(`Tentando aplicar zoom: ${targetZoom.toFixed(2)}`);

            try {
                await videoTrack.applyConstraints({
                    advanced: [{ zoom: targetZoom }]
                });
                currentZoom = targetZoom;
                statusEl.textContent = `Zoom: ${currentZoom.toFixed(2)}x`;
                // Se o zoom está no máximo, o próximo clique o levará ao mínimo.
                // Se o zoom está no mínimo, o próximo clique o levará para cima.
                zoomToggleBtn.textContent = (currentZoom >= max) ? "Redefinir Zoom" : "Zoom +";

            } catch (err) {
                console.error('Erro ao aplicar zoom:', err);
                statusEl.textContent = `Erro ao aplicar zoom: ${err.message}`;
            }
        }

        // --- 3. Event Listener para o Botão de Zoom Único ---
        zoomToggleBtn.addEventListener('click', toggleZoom);

        // --- 4. Inicialização da Aplicação ---

        // Inicia a câmera e, em seguida, carrega o modelo de IA
        async function initApp() {
            await startCamera();
            await loadModel();
        }

        initApp(); // Chama a função de inicialização
    </script>
</body>
</html>
