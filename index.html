<!DOCTYPE html>
<html lang="pt-BR">
<head>
<meta charset="UTF-8" />
<title>Reconhecimento Facial com Informações e Zoom</title>
<style>
  body, html {
    margin: 0; padding: 0; overflow: hidden;
    font-family: sans-serif;
    background: #000; color: #fff;
    display: flex; flex-direction: column; align-items: center; justify-content: center;
    height: 100vh;
  }
  video, canvas {
    position: absolute; top: 0; left: 0;
    width: 100vw; height: 100vh;
    object-fit: cover;
    transform: scaleX(-1); /* espelho para câmera frontal */
  }
  #info {
    position: fixed;
    bottom: 20px;
    background: rgba(0,0,0,0.5);
    padding: 10px 20px;
    border-radius: 10px;
    font-size: 18px;
    max-width: 90vw;
    z-index: 10;
    text-align: center;
    white-space: pre-wrap;
  }
  #zoomBtn {
    position: fixed;
    top: 10px; right: 10px;
    padding: 10px 15px;
    background: #007bff;
    border: none;
    color: white;
    font-size: 18px;
    border-radius: 8px;
    cursor: pointer;
    z-index: 10;
  }
</style>
</head>
<body>

<video id="video" autoplay muted playsinline></video>
<canvas id="canvas"></canvas>
<button id="zoomBtn">Zoom 1x</button>
<div id="info">Carregando modelos e câmera...</div>

<!-- face-api.js -->
<script defer src="https://cdn.jsdelivr.net/npm/face-api.js"></script>

<script>
  const video = document.getElementById('video');
  const canvas = document.getElementById('canvas');
  const ctx = canvas.getContext('2d');
  const info = document.getElementById('info');
  const zoomBtn = document.getElementById('zoomBtn');

  let mediaTrack;
  let zoomLevel = 1;

  // Pessoas conhecidas para reconhecimento (nomes + info + imagens para treinamento)
  const people = [
    { name: 'Maria', info: 'Arquiteta, 29 anos', images: 3 },
    { name: 'Joao', info: 'Professor, 35 anos', images: 3 },
    { name: 'Carlos', info: 'Engenheiro, 41 anos', images: 3 }
  ];

  // Carrega imagens rotuladas e gera descritores para reconhecimento
  async function loadLabeledImages() {
    return Promise.all(
      people.map(async person => {
        const descriptors = [];
        for(let i=1; i <= person.images; i++) {
          try {
            const img = await faceapi.fetchImage(`labeled/${person.name}/${i}.jpg`);
            const detection = await faceapi.detectSingleFace(img).withFaceLandmarks().withFaceDescriptor();
            if (detection) {
              descriptors.push(detection.descriptor);
            }
          } catch (err) {
            console.warn(`Erro ao carregar imagem ${person.name}/${i}:`, err);
          }
        }
        return new faceapi.LabeledFaceDescriptors(person.name, descriptors);
      })
    );
  }

  async function startCamera() {
    const stream = await navigator.mediaDevices.getUserMedia({
      video: { facingMode: "environment" } // câmera traseira
    });
    video.srcObject = stream;
    mediaTrack = stream.getVideoTracks()[0];
    return new Promise(resolve => video.onloadedmetadata = resolve);
  }

  async function toggleZoom() {
    if (!mediaTrack) {
      alert('Câmera não iniciada ou zoom não suportado');
      return;
    }
    const capabilities = mediaTrack.getCapabilities();
    if (!capabilities.zoom) {
      alert('Zoom não suportado nesse dispositivo');
      return;
    }
    zoomLevel = zoomLevel >= (capabilities.zoom.max || 3) ? (capabilities.zoom.min || 1) : zoomLevel + 1;
    await mediaTrack.applyConstraints({ advanced: [{ zoom: zoomLevel }] });
    zoomBtn.innerText = `Zoom ${zoomLevel}x`;
  }

  async function init() {
    info.innerText = 'Carregando modelos...';
    await Promise.all([
      faceapi.nets.tinyFaceDetector.loadFromUri('https://cdn.jsdelivr.net/npm/face-api.js/weights'),
      faceapi.nets.faceLandmark68Net.loadFromUri('https://cdn.jsdelivr.net/npm/face-api.js/weights'),
      faceapi.nets.faceRecognitionNet.loadFromUri('https://cdn.jsdelivr.net/npm/face-api.js/weights')
    ]);
    info.innerText = 'Modelos carregados. Inicializando câmera...';

    await startCamera();
    info.innerText = 'Carregando imagens rotuladas...';

    const labeledFaceDescriptors = await loadLabeledImages();
    const faceMatcher = new faceapi.FaceMatcher(labeledFaceDescriptors, 0.6);

    canvas.width = video.videoWidth;
    canvas.height = video.videoHeight;

    info.innerText = 'Pronto! Aproxima o rosto da câmera.';

    video.addEventListener('play', () => {
      const displaySize = { width: video.videoWidth, height: video.videoHeight };
      faceapi.matchDimensions(canvas, displaySize);

      setInterval(async () => {
        const detections = await faceapi
          .detectAllFaces(video, new faceapi.TinyFaceDetectorOptions())
          .withFaceLandmarks()
          .withFaceDescriptors();

        ctx.clearRect(0, 0, canvas.width, canvas.height);

        const resizedDetections = faceapi.resizeResults(detections, displaySize);

        faceapi.draw.drawDetections(canvas, resizedDetections);
        faceapi.draw.drawFaceLandmarks(canvas, resizedDetections);

        if (detections.length > 0) {
          let infoText = '';
          resizedDetections.forEach(detection => {
            const bestMatch = faceMatcher.findBestMatch(detection.descriptor);
            const person = people.find(p => p.name === bestMatch.label);
            if (person) {
              infoText += `${person.name} - ${person.info}\n\n`;
              // Você pode desenhar o nome na caixa:
              const box = detection.detection.box;
              ctx.fillStyle = 'lime';
              ctx.font = '20px Arial';
              ctx.fillText(person.name, box.x, box.y > 20 ? box.y - 10 : box.y + 25);
            } else {
              infoText += 'Pessoa não reconhecida\n\n';
            }
          });
          info.innerText = infoText.trim();
        } else {
          info.innerText = 'Nenhum rosto detectado.';
        }

      }, 1000);
    });
  }

  zoomBtn.addEventListener('click', toggleZoom);

  window.addEventListener('load', init);
</script>

</body>
</html>
