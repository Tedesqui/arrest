<!DOCTYPE html>
<html lang="pt-br">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Reconhecimento Facial AR - Mobile com Zoom</title>
    <script defer src="https://cdn.jsdelivr.net/npm/face-api.js"></script>
    <script src="https://aframe.io/releases/1.3.0/aframe.min.js"></script>
    <style>
        body, html {
            margin: 0;
            overflow: hidden;
            font-family: Arial, sans-serif;
            display: flex;
            flex-direction: column;
            justify-content: center;
            align-items: center;
            min-height: 100vh;
            background-color: #f0f0f0;
        }
        video {
            position: fixed;
            top: 0;
            left: 0;
            width: 100vw;
            height: 100vh;
            object-fit: cover;
            z-index: -1;
        }
        #overlay {
            position: absolute;
            top: 10px;
            left: 10px;
            background: rgba(0, 0, 0, 0.6);
            color: #fff;
            padding: 10px;
            border-radius: 8px;
            font-size: 16px;
            z-index: 10;
        }
        canvas {
            position: absolute;
            top: 0;
            left: 0;
            z-index: 0;
        }
        #controls {
            position: absolute;
            bottom: 20px;
            left: 50%;
            transform: translateX(-50%);
            z-index: 10;
        }
        button {
            padding: 12px 25px;
            font-size: 16px;
            cursor: pointer;
            border: none;
            border-radius: 30px;
            background-color: #007bff;
            color: white;
            box-shadow: 0 4px 8px rgba(0, 0, 0, 0.2);
            transition: background-color 0.3s ease, transform 0.2s ease;
            outline: none;
        }
        button:hover {
            background-color: #0056b3;
            transform: translateY(-2px);
        }
        button:active {
            transform: translateY(1px);
        }
        button:disabled {
            background-color: #cccccc;
            cursor: not-allowed;
            box-shadow: none;
        }
    </style>
</head>
<body>
    <video id="video" autoplay muted playsinline></video>

    <div id="overlay">Carregando IA e imagens...</div>

    <a-scene embedded vr-mode-ui="enabled: false">
        <a-text id="ar-label" value="" position="0 2 -3" color="yellow" scale="2 2 2"></a-text>
    </a-scene>

    <div id="controls">
        <button id="zoomToggleBtn" disabled>Zoom</button>
    </div>

    <script>
        const video = document.getElementById("video");
        const overlay = document.getElementById("overlay");
        const arLabel = document.getElementById("ar-label");
        const zoomToggleBtn = document.getElementById('zoomToggleBtn');

        const people = [
            { name: "Jean", info: "Criminoso Classe A, Condenado a 50 anos de prisão, Status: Foragido", images: 21 },
            { name: "Mariana", info: "Arquiteta, 29 anos", images: 13 },
            { name: "Elon", info: "Engenheiro, 41 anos", images: 7 }
        ];

        let videoTrack;
        let zoomCapabilities = {};
        let currentZoom = 1.0;

        async function loadLabeledImages() {
            return Promise.all(
                people.map(async person => {
                    const descriptors = [];
                    for (let i = 1; i <= person.images; i++) {
                        const imgPath = `labeled/${person.name}/${i}.jpg`;
                        try {
                            const img = await faceapi.fetchImage(imgPath);
                            const detection = await faceapi.detectSingleFace(img)
                                .withFaceLandmarks()
                                .withFaceDescriptor();
                            if (detection) {
                                descriptors.push(detection.descriptor);
                            }
                        } catch (err) {
                            console.warn(`Erro na imagem ${imgPath}:`, err);
                        }
                    }
                    return new faceapi.LabeledFaceDescriptors(person.name, descriptors);
                })
            );
        }

        async function startVideo() {
            try {
                const stream = await navigator.mediaDevices.getUserMedia({
                    video: { facingMode: { exact: "environment" } }
                });
                video.srcObject = stream;
                await new Promise(resolve => video.onloadedmetadata = resolve);

                videoTrack = stream.getVideoTracks()[0];
                if (videoTrack.getCapabilities) {
                    zoomCapabilities = videoTrack.getCapabilities();
                    if (zoomCapabilities.zoom) {
                        currentZoom = zoomCapabilities.zoom.min;
                        zoomToggleBtn.disabled = false;
                        overlay.innerText = `Zoom: ${currentZoom.toFixed(2)}x - Carregando IA...`;
                    }
                }
            } catch (err) {
                console.error("Erro ao acessar a câmera:", err);
                overlay.innerText = "Erro: Câmera não acessível.";
            }
        }

        zoomToggleBtn.addEventListener('click', () => {
            if (!videoTrack || !zoomCapabilities.zoom) return;
            const maxZoom = zoomCapabilities.zoom.max;
            currentZoom += 1;
            if (currentZoom > maxZoom) currentZoom = zoomCapabilities.zoom.min;
            videoTrack.applyConstraints({ advanced: [{ zoom: currentZoom }] });
            overlay.innerText = `Zoom: ${currentZoom.toFixed(2)}x`;
        });

        async function init() {
            overlay.innerText = "Carregando modelos de IA...";
            await Promise.all([
                faceapi.nets.tinyFaceDetector.loadFromUri("https://justadudewhohacks.github.io/face-api.js/models"),
                faceapi.nets.faceLandmark68Net.loadFromUri("https://justadudewhohacks.github.io/face-api.js/models"),
                faceapi.nets.faceRecognitionNet.loadFromUri("https://justadudewhohacks.github.io/face-api.js/models")
            ]);

            const labeledDescriptors = await loadLabeledImages();
            const faceMatcher = new faceapi.FaceMatcher(labeledDescriptors, 0.6);

            startVideo();

            video.addEventListener('play', () => {
                const canvas = faceapi.createCanvasFromMedia(video);
                document.body.append(canvas);
                const displaySize = { width: video.videoWidth, height: video.videoHeight };
                faceapi.matchDimensions(canvas, displaySize);

                setInterval(async () => {
                    const detections = await faceapi.detectAllFaces(video, new faceapi.TinyFaceDetectorOptions())
                        .withFaceLandmarks()
                        .withFaceDescriptors();

                    const resizedDetections = faceapi.resizeResults(detections, displaySize);
                    canvas.getContext('2d').clearRect(0, 0, canvas.width, canvas.height);
                    faceapi.draw.drawDetections(canvas, resizedDetections);

                    resizedDetections.forEach(detection => {
                        const bestMatch = faceMatcher.findBestMatch(detection.descriptor);
                        arLabel.setAttribute('value', bestMatch.toString());
                    });
                }, 1000);
            });
        }

        init();
    </script>
</body>
</html>
