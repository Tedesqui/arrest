<!DOCTYPE html>
<html lang="pt-BR">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Reconhecimento Facial em Tempo Real - Face-API.js</title>
    <!-- Tailwind CSS CDN para estilização moderna -->
    <script src="https://cdn.tailwindcss.com"></script>
    <!-- Face-API.js CDN para detecção e reconhecimento facial -->
    <script src="https://cdn.jsdelivr.net/npm/face-api.js@0.22.2/dist/face-api.min.js"></script>
    <style>
        /* Estilos personalizados para vídeo e canvas para garantir cobertura total e camadas */
        body, html {
            margin: 0;
            padding: 0;
            overflow: hidden;
            font-family: 'Inter', sans-serif;
            display: flex;
            flex-direction: column;
            align-items: center;
            justify-content: center;
            min-height: 100vh;
            background-color: #000;
            color: #fff;
        }
        video, canvas {
            position: fixed;
            top: 0;
            left: 0;
            width: 100vw;
            height: 100vh;
            object-fit: cover; /* Garante que o vídeo cubra toda a tela */
            z-index: 1; /* Vídeo e canvas ficam atrás dos elementos da UI */
        }
        /* Estilo para o spinner de carregamento */
        .spinner {
            border: 4px solid rgba(255, 255, 255, 0.3);
            border-top: 4px solid #fff;
            border-radius: 50%;
            width: 30px;
            height: 30px;
            animation: spin 1s linear infinite;
        }
        @keyframes spin {
            0% { transform: rotate(0deg); }
            100% { transform: rotate(360deg); }
        }
    </style>
</head>
<body class="bg-black text-white flex flex-col items-center justify-center h-screen w-screen">

    <video id="video" autoplay muted playsinline class="z-10"></video>
    <canvas id="canvas" class="z-20"></canvas>

    <!-- Caixa de Informações -->
    <div id="infoBox" class="fixed bottom-5 left-1/2 -translate-x-1/2 bg-gray-900 bg-opacity-70 p-4 rounded-xl text-center text-base max-w-sm sm:max-w-md md:max-w-lg lg:max-w-xl z-30 shadow-lg">
        <div id="infoContent">Carregando modelos de IA e câmera...</div>
        <div id="loadingSpinner" class="hidden mt-2 mx-auto spinner"></div>
    </div>

    <!-- Controles -->
    <div id="controls" class="fixed top-4 right-4 z-30 flex space-x-2">
        <button id="zoomButton" onclick="toggleZoom()" class="px-4 py-2 bg-blue-600 hover:bg-blue-700 text-white font-semibold rounded-lg shadow-md transition duration-300 ease-in-out transform hover:scale-105 focus:outline-none focus:ring-2 focus:ring-blue-500 focus:ring-opacity-75">
            Zoom 1x
        </button>
    </div>

    <script>
        // --- 1. Seletores de Elementos HTML ---
        const video = document.getElementById('video');
        const canvas = document.getElementById('canvas');
        const ctx = canvas.getContext('2d');
        const infoBox = document.getElementById('infoBox');
        const infoContent = document.getElementById('infoContent');
        const loadingSpinner = document.getElementById('loadingSpinner');
        const zoomButton = document.getElementById('zoomButton');

        // --- 2. Variáveis de Controle de Câmera e Zoom ---
        let track; // Representa a trilha de vídeo do stream da câmera
        let zoomLevel = 1; // Nível de zoom atual
        let isDetecting = false; // Flag para evitar múltiplos loops de detecção
        let modelsLoaded = false; // Flag para verificar se os modelos face-api.js foram carregados
        let faceMatcher = null; // Armazenará a instância do FaceMatcher

        // --- 3. Caminho para os Modelos Face-API.js ---
        // IMPORTANTE: Esta pasta 'models' DEVE existir na raiz do seu projeto no GitHub Pages
        // e conter os arquivos .json e .weights necessários para tinyFaceDetector, faceLandmark68Net e faceRecognitionNet.
        const MODEL_URL = '/models'; 

        // --- 4. Dados de Pessoas Conhecidas para Reconhecimento ---
        // Para cada pessoa que você quer reconhecer, adicione um objeto aqui.
        // O array 'descriptors' DEVE ser preenchido com os descritores faciais REAIS dessa pessoa.
        const knownPeople = [
            {
                name: 'Jean Tedesqui', // Altere para o seu nome ou o nome da pessoa principal
                bio: 'Esta é a pessoa que o aplicativo está configurado para reconhecer. Olá! Bem-vindo(a)! Você é o criador deste incrível sistema!',
                descriptors: [] // ESTE ARRAY SERÁ PREENCHIDO COM O(S) DESCRITOR(ES) REAL(IS) DO SEU ROSTO
            },
            {
                name: 'Elon Musk', // Exemplo de outra pessoa
                bio: 'Empresário, CEO da SpaceX e Tesla, impulsionando avanços em veículos elétricos e exploração espacial. Conhecido por suas ideias futuristas.',
                descriptors: [] // Será preenchido com descritores simulados para demonstração
            },
            {
                name: 'Mariana Ximenes', // Exemplo de outra pessoa
                bio: 'Atriz Brasileira, ícone do cinema e TV, conhecida por sua versatilidade e talento em diversas produções nacionais.',
                descriptors: [] // Será preenchido com descritores simulados para demonstração
            }
            // Adicione mais pessoas aqui conforme necessário
        ];

        // --- 5. Funções Assíncronas Principais ---

        /**
         * Carrega os modelos necessários do face-api.js.
         * Exibe o status de carregamento na caixa de informações.
         */
        async function loadModels() {
            infoContent.innerText = 'Carregando modelos de IA...';
            try {
                // Carrega apenas os modelos essenciais para detecção e reconhecimento
                await faceapi.nets.tinyFaceDetector.load(MODEL_URL);
                await faceapi.nets.faceLandmark68Net.load(MODEL_URL);
                await faceapi.nets.faceRecognitionNet.load(MODEL_URL); // Crucial para o reconhecimento
                
                modelsLoaded = true;
                infoContent.innerText = 'Modelos de IA carregados. Iniciando câmera...';
            } catch (error) {
                console.error('Erro ao carregar modelos do face-api.js:', error);
                infoContent.innerText = 'Erro: Não foi possível carregar os modelos de IA. Verifique o console e o caminho dos modelos.';
            }
        }

        /**
         * Inicia o feed da câmera, solicitando especificamente a câmera ambiente (traseira).
         * Lida com possíveis erros durante o acesso à câmera.
         */
        async function startCamera() {
            try {
                const stream = await navigator.mediaDevices.getUserMedia({
                    video: {
                        facingMode: { ideal: 'environment' }, // Prioriza a câmera traseira
                        width: { ideal: 1280 }, // Solicita resolução mais alta para melhor detecção
                        height: { ideal: 720 }
                    }
                });
                video.srcObject = stream;
                track = stream.getVideoTracks()[0];

                await new Promise((resolve) => {
                    video.onloadedmetadata = () => {
                        video.play();
                        resolve();
                    };
                });
                infoContent.innerText = 'Câmera iniciada. Aguardando detecção de rostos...';
            } catch (error) {
                console.error('Erro ao acessar a câmera:', error);
                infoContent.innerText = 'Erro: Não foi possível acessar a câmera. Por favor, verifique as permissões.';
            }
        }

        /**
         * Popula os descritores faciais para as pessoas conhecidas.
         * Para o seu rosto, você deve substituir o descritor simulado pelo seu descritor real.
         * Para outras pessoas, geramos descritores simulados para demonstração.
         */
        async function populateKnownFaceDescriptors() {
            // --- SEÇÃO A SER MODIFICADA PARA O SEU ROSTO ---
            // REMOVA A LINHA ABAIXO E COLE SEU DESCRITOR REAL AQUI!
            knownPeople[0].descriptors.push(new Float32Array(128).map(() => Math.random())); // Descritor SIMULADO para "Seu Rosto"
            // Exemplo de como seria um descritor real (copiado do console do script de extração):
            // knownPeople[0].descriptors.push(new Float32Array([0.123, 0.456, ..., 0.789]));
            // Você pode adicionar múltiplos descritores para a mesma pessoa (de diferentes fotos) para maior robustez:
            // knownPeople[0].descriptors.push(new Float32Array([...outro_descritor_real_seu...]));
            // --- FIM DA SEÇÃO A SER MODIFICADA ---

            // Descritores simulados para as outras pessoas (Elon Musk, Mariana Ximenes)
            knownPeople[1].descriptors.push(new Float32Array(128).map(() => Math.random()));
            knownPeople[2].descriptors.push(new Float32Array(128).map(() => Math.random()));


            // Crie LabeledFaceDescriptors para o FaceMatcher
            const labeledDescriptors = knownPeople.map(
                person => new faceapi.LabeledFaceDescriptors(person.name, person.descriptors)
            );

            // Crie o FaceMatcher com os descritores conhecidos
            // O limite de similaridade (0.6) pode ser ajustado:
            // - Menor valor = correspondência mais rigorosa (menos falsos positivos)
            // - Maior valor = correspondência mais flexível (mais chances de identificar, mas mais falsos positivos)
            faceMatcher = new faceapi.FaceMatcher(labeledDescriptors, 0.6);
        }

        /**
         * O loop principal de detecção. Captura continuamente frames de vídeo,
         * executa inferência do face-api.js e desenha caixas delimitadoras e informações.
         */
        async function detectLoop() {
            if (!modelsLoaded || !video.videoWidth || !video.videoHeight || !faceMatcher) {
                requestAnimationFrame(detectLoop);
                return;
            }

            canvas.width = video.videoWidth;
            canvas.height = video.videoHeight;

            const displaySize = { width: video.videoWidth, height: video.videoHeight };
            faceapi.matchDimensions(canvas, displaySize);

            // Detecta todos os rostos com pontos de referência e descritores
            const detections = await faceapi.detectAllFaces(video, new faceapi.TinyFaceDetectorOptions())
                .withFaceLandmarks()
                .withFaceDescriptors(); // Crucial para o reconhecimento

            const resizedDetections = faceapi.resizeResults(detections, displaySize);

            ctx.clearRect(0, 0, canvas.width, canvas.height); // Limpa o canvas

            let currentInfoBoxText = 'Nenhum rosto detetado.';

            if (resizedDetections.length > 0) {
                // Desenha as detecções no canvas
                faceapi.draw.drawDetections(canvas, resizedDetections);
                faceapi.draw.drawFaceLandmarks(canvas, resizedDetections);

                // Processa cada rosto detetado
                for (const detection of resizedDetections) {
                    const { detection: boxDetection, descriptor } = detection;
                    const box = boxDetection.box;

                    // Encontra a melhor correspondência usando FaceMatcher
                    const bestMatch = faceMatcher.findBestMatch(descriptor);
                    const recognizedName = bestMatch.label === 'unknown' ? 'Desconhecido' : bestMatch.label;
                    const matchDistance = Math.round(bestMatch.distance * 100) / 100; // Distância de correspondência

                    // Obtém a biografia da pessoa reconhecida
                    const recognizedPersonData = knownPeople.find(p => p.name === recognizedName);
                    const bio = recognizedPersonData ? recognizedPersonData.bio : 'Pessoa não identificada no banco de dados. Sem informações adicionais disponíveis.';

                    // Desenha o nome reconhecido e a distância de correspondência
                    const nameText = `${recognizedName} (${matchDistance})`;
                    new faceapi.draw.DrawTextField(
                        [nameText],
                        new faceapi.Point(box.x, box.y - 40) // Acima da caixa delimitadora
                    ).draw(canvas);

                    // Atualiza a caixa de informações para o primeiro rosto detectado
                    if (detection === resizedDetections[0]) {
                        currentInfoBoxText = `Rosto Detetado:\nNome: ${recognizedName}\nDistância: ${matchDistance}\nSobre: ${bio}`;
                    }
                }
            } else {
                currentInfoBoxText = `Nenhum rosto detetado.\n\nPosicione um rosto na câmera para detecção.`;
            }
            infoContent.innerText = currentInfoBoxText;

            requestAnimationFrame(detectLoop);
        }

        /**
         * Alterna o nível de zoom da câmera.
         * Fornece feedback visual e lida com recursos de zoom não suportados.
         */
        function toggleZoom() {
            zoomLevel = zoomLevel >= 3 ? 1 : zoomLevel + 1; // Cicla entre 1x, 2x, 3x
            zoomButton.innerText = `Zoom ${zoomLevel}x`;

            if (track && track.getCapabilities().zoom) {
                track.applyConstraints({ advanced: [{ zoom: zoomLevel }] })
                    .catch(e => {
                        console.warn('Erro ao aplicar zoom:', e);
                        infoContent.innerText = `Zoom não suportado ou erro: ${e.message}`;
                    });
            } else {
                infoContent.innerText = 'A função de zoom não é suportada por esta câmera.';
                zoomButton.disabled = true;
            }
        }

        // --- 6. Inicialização da Aplicação ---
        /**
         * Inicializa o aplicativo: carrega modelos, prepara descritores e inicia a câmera e o loop de detecção.
         */
        async function init() {
            infoContent.innerText = 'Carregando modelos de IA...';
            await loadModels();
            if (modelsLoaded) {
                infoContent.innerText = 'Modelos de IA carregados. Preparando descritores faciais...';
                await populateKnownFaceDescriptors(); // Preenche os descritores dos rostos conhecidos e cria o FaceMatcher
                infoContent.innerText = 'Descritores preparados. Iniciando câmera...';
                await startCamera();
                if (video.srcObject && !isDetecting) {
                    isDetecting = true;
                    detectLoop();
                }
            }
        }

        // Inicializa o aplicativo quando a janela carrega
        window.onload = init;
    </script>

</body>
</html>
