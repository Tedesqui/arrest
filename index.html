<!DOCTYPE html>
<html lang="pt-BR">
<head>
  <meta charset="UTF-8">
  <title>Reconhecimento Facial com Informações - TensorFlow.js + Roboflow</title>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@4.14.0/dist/tf.min.js"></script>
  <style>
    body, html {
      margin: 0;
      padding: 0;
      overflow: hidden;
      background: #000;
      color: #fff;
      font-family: Arial, sans-serif;
    }

    video, canvas {
      position: fixed;
      top: 0;
      left: 0;
      width: 100vw;
      height: 100vh;
      object-fit: cover;
    }

    #infoBox {
      position: fixed;
      bottom: 20px;
      left: 50%;
      transform: translateX(-50%);
      background: rgba(0, 0, 0, 0.7);
      padding: 15px 20px;
      border-radius: 10px;
      font-size: 16px;
      max-width: 90%;
      white-space: pre-line;
      text-align: center;
      z-index: 3;
    }

    #controls {
      position: fixed;
      top: 10px;
      right: 10px;
      z-index: 3;
    }

    button {
      padding: 10px 15px;
      border-radius: 10px;
      border: none;
      background-color: #007bff;
      color: white;
      cursor: pointer;
      font-size: 16px;
    }
  </style>
</head>
<body>

  <video id="video" autoplay muted playsinline></video>
  <canvas id="canvas"></canvas>

  <div id="infoBox">Carregando IA e câmera...</div>

  <div id="controls">
    <button onclick="toggleZoom()">Zoom 1x</button>
  </div>

  <script>
    const video = document.getElementById('video');
    const canvas = document.getElementById('canvas');
    const ctx = canvas.getContext('2d');
    const infoBox = document.getElementById('infoBox');

    let model;
    let track;
    let zoomLevel = 1;

    const personInfo = {
      0: { name: 'Jean Tedesqui', info: 'Empreendedor e Criador Digital' },
      1: { name: 'Mariana Ximenes', info: 'Atriz Brasileira, ícone do cinema e TV' },
      2: { name: 'Elon Musk', info: 'Empresário, CEO da SpaceX e Tesla' }
    };

    async function startCamera() {
      const stream = await navigator.mediaDevices.getUserMedia({
        video: { facingMode: { ideal: 'environment' }, width: 640, height: 480 }
      });
      video.srcObject = stream;
      track = stream.getVideoTracks()[0];
    }

    async function loadModel() {
      model = await tf.loadGraphModel('https://YOUR-ROBOFLOW-LINK/model.json');
      infoBox.innerText = 'Modelo carregado. Aproxime um rosto.';
    }

    function mapPerson(index) {
      return personInfo[index] || { name: 'Desconhecido', info: 'Sem informações disponíveis' };
    }

    async function detectLoop() {
      canvas.width = video.videoWidth;
      canvas.height = video.videoHeight;

      const imgTensor = tf.browser.fromPixels(video).div(255).expandDims(0);
      const predictions = await model.executeAsync(imgTensor);

      const boxes = predictions[1].arraySync()[0];
      const scores = predictions[2].arraySync()[0];
      const classes = predictions[3].arraySync()[0];

      ctx.clearRect(0, 0, canvas.width, canvas.height);

      let detectedPeople = [];

      boxes.forEach((box, i) => {
        if (scores[i] > 0.6) {
          const [y1, x1, y2, x2] = box;
          const left = x1 * canvas.width;
          const top = y1 * canvas.height;
          const width = (x2 - x1) * canvas.width;
          const height = (y2 - y1) * canvas.height;

          const person = mapPerson(classes[i]);

          ctx.strokeStyle = 'lime';
          ctx.lineWidth = 3;
          ctx.strokeRect(left, top, width, height);

          ctx.fillStyle = 'black';
          ctx.fillRect(left, top - 25, 160, 20);

          ctx.fillStyle = 'white';
          ctx.font = '14px Arial';
          ctx.fillText(person.name, left + 5, top - 10);

          detectedPeople.push(`${person.name}\n${person.info}`);
        }
      });

      infoBox.innerText = detectedPeople.length > 0 ? detectedPeople.join('\n\n') : 'Nenhum rosto detectado.';

      tf.dispose(imgTensor);
      predictions.forEach(p => p.dispose());

      requestAnimationFrame(detectLoop);
    }

    function toggleZoom() {
      zoomLevel = zoomLevel >= 3 ? 1 : zoomLevel + 1;
      document.querySelector('#controls button').innerText = `Zoom ${zoomLevel}x`;
      if (track && track.getCapabilities().zoom) {
        track.applyConstraints({ advanced: [{ zoom: zoomLevel }] });
      }
    }

    async function init() {
      await startCamera();
      await loadModel();
      detectLoop();
    }

    init();
  </script>

</body>
</html>
